{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO</span> Loading knowledge base                                                                                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO\u001b[0m Loading knowledge base                                                                                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO</span> Added <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> documents to knowledge base                                                                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO\u001b[0m Added \u001b[1;36m0\u001b[0m documents to knowledge base                                                                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from agno.agent import Agent\n",
    "from agno.document.base import Document\n",
    "from agno.knowledge.document import DocumentKnowledgeBase\n",
    "from agno.vectordb.pgvector import PgVector\n",
    "from agno.embedder.ollama import OllamaEmbedder\n",
    "\n",
    "\n",
    "\n",
    "fun_facts = \"\"\"\n",
    "- Earth is the third planet from the Sun and the only known astronomical object to support life.\n",
    "- Approximately 71% of Earth's surface is covered by water, with the Pacific Ocean being the largest.\n",
    "- The Earth's atmosphere is composed mainly of nitrogen (78%) and oxygen (21%), with traces of other gases.\n",
    "- Earth rotates on its axis once every 24 hours, leading to the cycle of day and night.\n",
    "- The planet has one natural satellite, the Moon, which influences tides and stabilizes Earth's axial tilt.\n",
    "- Earth's tectonic plates are constantly shifting, leading to geological activities like earthquakes and volcanic eruptions.\n",
    "- The highest point on Earth is Mount Everest, standing at 8,848 meters (29,029 feet) above sea level.\n",
    "- The deepest part of the ocean is the Mariana Trench, reaching depths of over 11,000 meters (36,000 feet).\n",
    "- Earth has a diverse range of ecosystems, from rainforests and deserts to coral reefs and tundras.\n",
    "- The planet's magnetic field protects life by deflecting harmful solar radiation and cosmic rays.\n",
    "\"\"\"\n",
    "\n",
    "embedder=OllamaEmbedder(id=\"nomic-embed-text:latest\", dimensions=768) # 3072\n",
    "\n",
    "# Load documents from the data/docs directory\n",
    "documents = [Document(content=fun_facts)]\n",
    "\n",
    "# Database connection URL\n",
    "db_url = \"postgresql+psycopg://ai:ai@localhost:5532/ai\"\n",
    "vector_db = PgVector(\n",
    "        table_name=\"new-documents\",\n",
    "        db_url=db_url,\n",
    "        embedder=embedder,\n",
    "    )\n",
    "\n",
    "# Create a knowledge base with the loaded documents\n",
    "knowledge_base = DocumentKnowledgeBase(\n",
    "    documents=documents,\n",
    "    vector_db=vector_db,\n",
    "    \n",
    ")\n",
    "\n",
    "# Load the knowledge base\n",
    "knowledge_base.load(recreate=False)\n",
    "\n",
    "# Create an agent with the knowledge base\n",
    "agent = Agent(\n",
    "    knowledge=knowledge_base,\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: chromadb in /home/hb/anaconda3/lib/python3.12/site-packages (1.0.0)\n",
      "Requirement already satisfied: build>=1.0.3 in /home/hb/anaconda3/lib/python3.12/site-packages (from chromadb) (1.2.2.post1)\n",
      "Requirement already satisfied: pydantic>=1.9 in /home/hb/anaconda3/lib/python3.12/site-packages (from chromadb) (2.10.6)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.6 in /home/hb/anaconda3/lib/python3.12/site-packages (from chromadb) (0.7.6)\n",
      "Requirement already satisfied: fastapi==0.115.9 in /home/hb/anaconda3/lib/python3.12/site-packages (from chromadb) (0.115.9)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in /home/hb/anaconda3/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.34.0)\n",
      "Requirement already satisfied: numpy>=1.22.5 in /home/hb/anaconda3/lib/python3.12/site-packages (from chromadb) (2.2.2)\n",
      "Requirement already satisfied: posthog>=2.4.0 in /home/hb/anaconda3/lib/python3.12/site-packages (from chromadb) (3.18.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /home/hb/anaconda3/lib/python3.12/site-packages (from chromadb) (4.12.2)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /home/hb/anaconda3/lib/python3.12/site-packages (from chromadb) (1.19.2)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /home/hb/anaconda3/lib/python3.12/site-packages (from chromadb) (1.30.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /home/hb/anaconda3/lib/python3.12/site-packages (from chromadb) (1.30.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /home/hb/anaconda3/lib/python3.12/site-packages (from chromadb) (0.51b0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /home/hb/anaconda3/lib/python3.12/site-packages (from chromadb) (1.30.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /home/hb/anaconda3/lib/python3.12/site-packages (from chromadb) (0.21.0)\n",
      "Requirement already satisfied: pypika>=0.48.9 in /home/hb/anaconda3/lib/python3.12/site-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /home/hb/anaconda3/lib/python3.12/site-packages (from chromadb) (4.67.1)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /home/hb/anaconda3/lib/python3.12/site-packages (from chromadb) (7.4.0)\n",
      "Requirement already satisfied: importlib-resources in /home/hb/anaconda3/lib/python3.12/site-packages (from chromadb) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /home/hb/anaconda3/lib/python3.12/site-packages (from chromadb) (1.70.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /home/hb/anaconda3/lib/python3.12/site-packages (from chromadb) (4.3.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in /home/hb/anaconda3/lib/python3.12/site-packages (from chromadb) (0.15.1)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in /home/hb/anaconda3/lib/python3.12/site-packages (from chromadb) (32.0.1)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in /home/hb/anaconda3/lib/python3.12/site-packages (from chromadb) (9.0.0)\n",
      "Requirement already satisfied: pyyaml>=6.0.0 in /home/hb/anaconda3/lib/python3.12/site-packages (from chromadb) (6.0.2)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in /home/hb/anaconda3/lib/python3.12/site-packages (from chromadb) (5.1.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in /home/hb/anaconda3/lib/python3.12/site-packages (from chromadb) (3.10.15)\n",
      "Requirement already satisfied: httpx>=0.27.0 in /home/hb/anaconda3/lib/python3.12/site-packages (from chromadb) (0.28.1)\n",
      "Requirement already satisfied: rich>=10.11.0 in /home/hb/anaconda3/lib/python3.12/site-packages (from chromadb) (13.9.4)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in /home/hb/anaconda3/lib/python3.12/site-packages (from chromadb) (4.23.0)\n",
      "Requirement already satisfied: starlette<0.46.0,>=0.40.0 in /home/hb/anaconda3/lib/python3.12/site-packages (from fastapi==0.115.9->chromadb) (0.45.3)\n",
      "Requirement already satisfied: packaging>=19.1 in /home/hb/anaconda3/lib/python3.12/site-packages (from build>=1.0.3->chromadb) (24.2)\n",
      "Requirement already satisfied: pyproject_hooks in /home/hb/anaconda3/lib/python3.12/site-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
      "Requirement already satisfied: anyio in /home/hb/anaconda3/lib/python3.12/site-packages (from httpx>=0.27.0->chromadb) (4.8.0)\n",
      "Requirement already satisfied: certifi in /home/hb/anaconda3/lib/python3.12/site-packages (from httpx>=0.27.0->chromadb) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /home/hb/anaconda3/lib/python3.12/site-packages (from httpx>=0.27.0->chromadb) (1.0.7)\n",
      "Requirement already satisfied: idna in /home/hb/anaconda3/lib/python3.12/site-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/hb/anaconda3/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /home/hb/anaconda3/lib/python3.12/site-packages (from jsonschema>=4.19.0->chromadb) (25.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/hb/anaconda3/lib/python3.12/site-packages (from jsonschema>=4.19.0->chromadb) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/hb/anaconda3/lib/python3.12/site-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/hb/anaconda3/lib/python3.12/site-packages (from jsonschema>=4.19.0->chromadb) (0.22.3)\n",
      "Requirement already satisfied: six>=1.9.0 in /home/hb/anaconda3/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /home/hb/anaconda3/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /home/hb/anaconda3/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (2.38.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /home/hb/anaconda3/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
      "Requirement already satisfied: requests in /home/hb/anaconda3/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (2.32.3)\n",
      "Requirement already satisfied: requests-oauthlib in /home/hb/anaconda3/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /home/hb/anaconda3/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in /home/hb/anaconda3/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (2.3.0)\n",
      "Requirement already satisfied: durationpy>=0.7 in /home/hb/anaconda3/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (0.9)\n",
      "Requirement already satisfied: coloredlogs in /home/hb/anaconda3/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /home/hb/anaconda3/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
      "Requirement already satisfied: protobuf in /home/hb/anaconda3/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb) (5.29.3)\n",
      "Requirement already satisfied: sympy in /home/hb/anaconda3/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /home/hb/anaconda3/lib/python3.12/site-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.18)\n",
      "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /home/hb/anaconda3/lib/python3.12/site-packages (from opentelemetry-api>=1.2.0->chromadb) (7.0.1)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /home/hb/anaconda3/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.66.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.30.0 in /home/hb/anaconda3/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.30.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.30.0 in /home/hb/anaconda3/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.30.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.51b0 in /home/hb/anaconda3/lib/python3.12/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.51b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.51b0 in /home/hb/anaconda3/lib/python3.12/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.51b0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.51b0 in /home/hb/anaconda3/lib/python3.12/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.51b0)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.51b0 in /home/hb/anaconda3/lib/python3.12/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.51b0)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /home/hb/anaconda3/lib/python3.12/site-packages (from opentelemetry-instrumentation==0.51b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.14.1)\n",
      "Requirement already satisfied: asgiref~=3.0 in /home/hb/anaconda3/lib/python3.12/site-packages (from opentelemetry-instrumentation-asgi==0.51b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
      "Requirement already satisfied: monotonic>=1.5 in /home/hb/anaconda3/lib/python3.12/site-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /home/hb/anaconda3/lib/python3.12/site-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: distro>=1.5.0 in /home/hb/anaconda3/lib/python3.12/site-packages (from posthog>=2.4.0->chromadb) (1.9.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/hb/anaconda3/lib/python3.12/site-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /home/hb/anaconda3/lib/python3.12/site-packages (from pydantic>=1.9->chromadb) (2.27.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/hb/anaconda3/lib/python3.12/site-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/hb/anaconda3/lib/python3.12/site-packages (from rich>=10.11.0->chromadb) (2.19.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /home/hb/anaconda3/lib/python3.12/site-packages (from tokenizers>=0.13.2->chromadb) (0.28.1)\n",
      "Requirement already satisfied: click>=8.0.0 in /home/hb/anaconda3/lib/python3.12/site-packages (from typer>=0.9.0->chromadb) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /home/hb/anaconda3/lib/python3.12/site-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
      "Requirement already satisfied: httptools>=0.6.3 in /home/hb/anaconda3/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /home/hb/anaconda3/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.1)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /home/hb/anaconda3/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /home/hb/anaconda3/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.4)\n",
      "Requirement already satisfied: websockets>=10.4 in /home/hb/anaconda3/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (14.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/hb/anaconda3/lib/python3.12/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/hb/anaconda3/lib/python3.12/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/hb/anaconda3/lib/python3.12/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
      "Requirement already satisfied: filelock in /home/hb/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/hb/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2024.6.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/hb/anaconda3/lib/python3.12/site-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.17.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/hb/anaconda3/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/hb/anaconda3/lib/python3.12/site-packages (from requests->kubernetes>=28.1.0->chromadb) (3.4.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/hb/anaconda3/lib/python3.12/site-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /home/hb/anaconda3/lib/python3.12/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/hb/anaconda3/lib/python3.12/site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /home/hb/anaconda3/lib/python3.12/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "from typing import List\n",
    "from agno.document import Document\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def youtube_parser(video_url: str) -> List[Document]:\n",
    "    yt_vid_id = video_url.split(\"v=\")[1]\n",
    "    transcript_list = YouTubeTranscriptApi.list_transcripts(yt_vid_id)\n",
    "    subtitle = None\n",
    "\n",
    "    for transcript in transcript_list:\n",
    "        if transcript.language_code == \"en\":\n",
    "            subtitle = transcript.fetch()\n",
    "            break\n",
    "        else:\n",
    "            subtitle = transcript.translate('en').fetch()\n",
    "            break\n",
    "\n",
    "    if subtitle is None:\n",
    "        raise ValueError(\"No subtitles found or translation failed.\")\n",
    "\n",
    "    transcript_text = \"\\n\".join([sub['text'] for sub in subtitle])\n",
    "\n",
    "    # Create a Document object\n",
    "    doc = Document(\n",
    "        content=transcript_text,\n",
    "    )\n",
    "\n",
    "    return [doc]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(content=\"in this video I'm going to show you how\\nto completely automate your invoice\\nprocessing with a human in the loop\\napproach meaning that you will have the\\nability to interact with this automation\\nright from your phone this will be a\\nstep-by-step process meaning once this\\nautomation processes One Step it's going\\nto wait for your response to make sure\\nit understands your decision before\\nmoving on to the next step and\\nprocessing the next step of this\\nautomation so I'm going to go ahead and\\nstart with a demo and then I'm going to\\ncome back and walk through step by step\\nand show you what these different nodes\\nare and how this thing will work if you\\nwere to to import this on your own\\nworkflow all right so right now on the\\nleft hand side you can see this is my\\ntelegram account again I'm using\\ntelegram but you can use WhatsApp or\\nyour phone as well if you want to build\\nthose automations yourself uh but on the\\nright hand side this is my workflow you\\ncan see on the left hand side I already\\nuh did a few examples but I'm going to\\ngo ahead and upload a new invoice here\\nas an image and then also as a document\\nbecause this is able to process an image\\nuh a document and also a text as well\\nand again like I said I'll come back and\\nexplain the different steps and how it's\\nachieving this but for the uh demo\\npurposes let's go ahead and click on\\ntest workflow for now and then I'm going\\nto go ahead and whoops I didn't want\\nthat to good process that was from\\nbefore so let me go ahead and click on\\ntest workflow now and then I'm going to\\nupload a new invoice so I'm going to go\\nahead and upload a photo and I already\\nhave these downloads right here so this\\nis an example invoice so let me actually\\nput that up this is from zil Electronics\\nagain I just grabbed this from online\\nfrom Google uh but this is just an\\nexample\\num invoice here as you can see the\\nbalance it says do 23\\n3835 so let's go ahead and upload this\\nand now it should be able to process\\nthat so I'm going to click on this go to\\nphotos upload the Excel invoice here and\\nI'm going to click on set oh actually\\nbefore I do that I need to make sure I'm\\nclicking on test workflow all right so\\nnow that's waiting for the trigger event\\nI'm going to press send and now it's\\ngoing to go ahead and process this right\\nhere so now it's uh going to add this to\\nthis image section and again I'm going\\nto walk through and show you what's\\nhappening here because based on a\\ndifferent switch based on the file if\\nit's an image or a PDF or text this is\\ngoing to go to different now right now\\nit's going to this um image route as you\\ncan see it's utilizing this uh llama\\nparse um and again I'm going to walk\\nthrough what the Llama parse is I'll\\nshow you exactly how you can create your\\naccount there an API account but\\nessentially it's going through and\\nprocessing this invoice it's extracting\\nit right now uh what is happening is\\nit's checking the status and then based\\non the status if it's pending it's going\\nto keep going through this weight Loop\\nand then based on uh that status once\\ngets updated then once it says success\\nit's going to go ahead and parse that\\nand add it to our Google sheet and then\\nit's going to also add that info to our\\nGoogle drive as well so let's go ahead\\nand wait for this to uh get\\nprocessed all right there you go so it\\nwent through it got processed now it's\\ngoing to add it to Google sheet and this\\nis where the human Loop comes in because\\nnow on the left hand side as you can see\\nI received the matage saying please\\ncheck and confirm the invoice number the\\ninvoice date the total amount so all of\\nthis once the data is correct now I'm\\ngiving the option to have these two\\nbuttons that says yes or no and this is\\nwhere that human in the loop comes in\\nbecause now it's interacting with me\\nright and now based on my selection it's\\ngoing to now process so if I say yes or\\nno different automation route is going\\nto get activated so if I say yes now you\\nwill see that uh this is going to get\\nprocessed through so if I click on yes\\nnow you'll\\nsee and I test\\nworkflow so now there you go now it went\\nthrough and it said okay now that we\\nsaid yes this data looks corre correct\\nnow it's going to ask us which payment\\nmethod was used to pay this invoice\\nright so we have three options card bank\\nor cash I'm going to go ahead and select\\ncard and then same thing based on my\\nselection it's going to go ahead and\\nprocess another route of this automation\\nso I'm going to again click on test\\nworkflow here and then I'm going to say\\nthis was processed with card let's say\\nokay now there you go so now it's going\\nthrough this route and it's going to\\nupdate another Google sheet with all of\\nthe data to make sure that it's updated\\nand it's also going to move this f move\\nthis info into our Google Drive and then\\nit's going to send us a message saying\\nthat oops successfully added uh updated\\nthe database so if I now go to my Google\\nsheet here as you can see it just\\nprocessed this invoice that is 2338 and.\\n35 with a tax of 11\\n$11.35 and then also the payment method\\nis card and again this payment method\\nit's absorbing based on our selection\\nlet's jump into the tutorial I'm going\\nto go ahead and start with a fresh\\nworkflow and then I'm going to import\\nthis and then go through step by step on\\nthe different nodes and the different um\\noptions when it comes to this Automation\\nand then we can test out the PDF as well\\nall right so I'm on my blank workflow\\nhere I'm going to go ahead and grab this\\ntemplate right here so let me go ahead\\nand come down\\nhere download this template click on\\ndownload and now I'm going to go and\\nupload this from\\nhere import from file all right awesome\\nso let's go ahead and name this invoice\\nagent\\ninvoice automation all right so the\\nfirst thing is we're using telegram\\ntrigger obviously um I love telegram\\nbecause it's one of the um easiest way\\nto test out the different automation but\\nlike I said you can if you have like\\nWhatsApp or you can even connect your\\nphone through twio it's the process\\nshould be the same thing um and you can\\nfollow other tutorials there lots of\\ntutorials on YouTube on how to do that\\nbut it's going to be the same exact way\\nas far as the process is concerned so\\nI've attached my telegram trigger and\\nthis is going to be listening for\\nmessages that's coming in the next step\\nis and we need to add a switch node\\nbecause we need to be able to process\\ndifferent uh invoices right so if an\\ninvoice is a PDF we need to process that\\nthat if it is a photo or if it's a text\\nwe need be able to process all of them\\nat the same time so let's go ahead and\\nI'm going to pull up my um another\\nexample invoice so this one's a PDF one\\nso if I go ahead and pull this up oh\\nthat's\\nhuge all right so this is a sample again\\nanother sample uh PDF for\\n$755 so we should be I'm going to go\\nahead and upload this and this should be\\nable to parse and grab all of that\\ninformation so let's go ahead and now\\nclick on test workflow again I'm going\\nto bring up\\nactually uh my telegram here there we go\\nso let's go ahead and add that actually\\nlet\\nme do this all right so I'm waiting for\\ntrigger event so let's go ahead and add\\nthat and this time I'm going to add a\\nfile and I'm going to grab this PDF\\ninvoice yep click on send\\nall right so there we go right now\\nwhat's happening is it's going to the\\ntop here and I'm going to let this\\nfinish and then I'm going to come back\\nand explain exactly what's going on\\nbecause this would have already\\nprocessed uh this uh step already right\\nso let's go ahead and let this thing\\nfinish and perfect it looks like came in\\nthrough all right so now as you can see\\non the left hand side I received your\\nPDF it's in process now so as soon as\\nyou send a file or you send or upload a\\nimage it's going to send you message\\nsaying it is processing this thing now\\nand now once it gets processed it's\\ngoing to tell you to please check the\\ndata and then based on yes or no it'll\\nbe able to go on to the next step but\\nlet's go ahead and take a look at what's\\nhappening here so once we add this\\ntelegram as you can see now I'm\\nreceiving that information and this time\\nobviously I received the file the PDF\\nfile so the next step what we need to do\\nis through the switch node as you can\\nsee we need to add we need to grab this\\nuh content from the document so what I'm\\ndoing is essentially just saying json.\\nmessage. doent and this is coming in\\nfrom the telegram so we're literally\\nusing our schema here uh to grab our\\ndocument right and it has a file ID here\\num and then also a bunch of other\\ninformation but that's what we're doing\\nwe're making sure that we're uh giving\\nthis the ability to process document\\nimage and the text as well in this case\\nas you can see the document is green\\nmeaning that this is automatically\\nrecognizing that this thing is a\\ndocument so now it's processing that\\nwith a file ID right here so now after\\nthat switch note this is going to send\\nthis based on uh so let me quickly zoom\\nin here as you can see there's document\\nimage and text so now since this is\\ndocument this is going to send this to\\nthe top so here what's happening is\\nafter that we're putting an edit field\\nor the set Noe which is basically going\\nto clean up the data that's coming in\\nout of our um uh switch node here right\\nso we're going to grab our chat ID\\nbecause we need to be able to respond um\\nback to our or user from the chat ID uh\\nwe need to grab the message and then we\\nalso grab the file ID that document that\\nwas uploaded here so the output as you\\ncan see it's pretty nice and clean and\\nwe're just getting uh the first name\\nlast name and then also the file ID of\\nthat uploaded document that went through\\nso afterward immediately we're sending a\\nmessage back to the user uh saying that\\nreceived your PDF or received your file\\nit is in process right now right so as\\nyou can see right here we're grabbing\\nthat chat ID to be able to interact with\\nthe user here and so this is what we're\\ndoing we're sending in a text saying hey\\nreceived your PDF it's in process now\\nyou can do whatever or add something\\nelse here it's completely customizable\\nand then you uh leave the reply because\\nagain we don't need to have an\\nadditional interface option at this\\npoint so once you uh send that\\ninformation now the user is aware as\\nthat the document is being processed and\\nthe next thing is we need to grab the\\nfile we need to download the file here\\nand as you can see in this telegram node\\nwe're able to grab that file downloaded\\nand then now we're sending this or\\nuploading this to uh llap pars now again\\nllama parse is a um one of the services\\nthat is provided by llama index and you\\ncan go ahead and take a look at llama\\nindex it's a very powerful website that\\nhas a lot of several a lot of\\nfunctionalities but one of it is you can\\nuh use their API to be able to upload a\\ndocument par the information and be able\\nto send uh all of the information that\\nit has been uh processed or retrieved to\\nadditional nodes right so it's the same\\nthing it's a very simple API parameter\\nso you just grab your apis here and then\\nalso give it the body parser so the way\\nto do this is if you just go to llama\\nindex so I'm going to go ahead and show\\nyou what llama index is as you can see\\nllama index it says build AI knowledge\\nassistance over your Enterprise and this\\nis one of the most popular um tools out\\nthere again because it it's used in\\nEnterprise solution it's used for uh\\nsmall businesses mediumsized businesses\\nit has a lot of different um\\nIntegrations and a lot of different\\noptions when it comes to like for\\nexample the framework um it has um\\ndocument parsing and this is one of my\\nfavorite uh document parsers because it\\nis very widely used so the great thing\\nis you can use their API to be able to\\ninteract with it directly from naden and\\nthat's what we're doing we're using this\\nendpoint called api. cloud. Lama index a\\nAPI parsing and upload right so this in\\nthis step we're uploading the file um\\nand then the next step what we're doing\\nis now we're going to get the status of\\nthe processing so what's happening here\\nCU this is very very important in this\\nuh node we're uploading the file but in\\nthe next note we're retrieving the\\nstatus of that upload or of that parsing\\nuh function basically right so this is\\ngoing to send us a status um of that\\nparticular job again quote unquote job\\nbecause that's what the endp point is\\nand based on the status we need to be\\nable to send this to additional Lo so\\nfor example if the job is successful\\nthen great right we're going to send it\\nto the next noes to be processed but if\\nit says pending then we need to set a\\nweight Noe here so that way our workflow\\nautomation does not stop or uh doesn't\\nbreak so therefore we're basically\\nlooping this so we're waiting for this\\nstatus to change from pending to ready\\nor to success and then we're going to\\nshift this off to the next steps of our\\nautomation so that's why we're adding\\nthis uh switch node here again we're\\nwaiting for the status to get to success\\nand that's when we will we'll move it to\\nthe next step but if the error shows any\\nkind of error we need be able to stop\\nthat workflow automation or if it's\\ncanceled same thing but if it's pending\\nwe're sending it to this uh route where\\nthis is going to just wait 1 second so\\nthis is just a note that says wait 1\\nsecond and it's going to keep Loop until\\nthat status changes to success once so\\nas you can see right\\nhere once it's successful or once we get\\nthe status of success now we're going to\\ngo ahead and send this to another note\\nand now we'll be able to actually parse\\nthe document that's inside this uh um or\\nthe the document that was uploaded right\\nso once and again this is another\\nendpoint right so this is another\\nendpoint same thing L index a/ API\\nparsing we need to add the job and then\\nalso the result markdown right because\\nnow we need to be able to uh U grab the\\noutput and then send this to our basic\\nllm chain we don't need to put an AI\\nagent here because again all we're doing\\nis grabbing the information we're using\\na structured output parser to be able to\\nuh take that information that was parsed\\nfrom the document put it in a Google\\nsheet so therefore a basic CH llm chain\\nis plenty here and again you're just\\ngiving a system prompt you know you're\\ntelling this thing that um hey you're\\nworld's leading expert in document data\\nextraction specialize in accuracy\\nidentifying blah blah blah just standard\\nagain you can use your um chat GPT or\\ncloth to be able to grab this prompt\\nhere and you're giving it proper\\ninstructions and then also we're giving\\nit an example of what the Json output\\nwould look like right in our case we're\\ng grabbing the invoice number the\\ninvoice date the total amount and then\\nalso the tax right so you can add\\nadditional stuff uh stuff in there as\\nwell we're just\\nadding um detailed prompt to make sure\\nwe're getting the exact information that\\nwe're looking for as far as the format\\nand then the formatting we're putting in\\noutput parser right here again same\\nthing use your chat PTR Cloud to be able\\nto um identify exactly what kind of a\\nresponse you want to achieve from this\\nbasic llm chain so once it does that now\\nwe're using our Google sheet to\\nbasically grab the SCH schema or grab\\nthis information which again we're\\ngetting this voice number invoice date\\ntotal amount and then tax right and\\nwe're just putting that on our Google\\nsheet which here has four columns\\ninvoice number date total amount tax\\npayment method this is later on but for\\nnow we're just adding our updating these\\nfour columns right\\nhere so once we're done with that step\\nnow we're sending a message to the user\\nback uh to make sure they check right so\\nright\\nhere let me quickly show you inside\\nthere you go so now we're saying please\\ncheck and confirm and the left hand side\\nas you can see on my here I'm showing\\nexactly that so and then also is all the\\ndata correct same thing you can add\\nwhatever you want here and now we're\\ngiving these additional two information\\nin the bottom right here so as you can\\nsee we're seeing reply keyboard right\\nand then we're adding two different\\noptions one is going to be yes and one\\nis going to be a no so this is how you\\ncan add an interactive way to\\ncommunicate with your user by adding\\nthis reply to keyboard right and again\\nthis is just an option that's within the\\ntelegram node here\\nso now once that is um um once that's\\nprocessed so now we're going to go ahead\\nand grab that file right and then we\\nneed to also add this to our uh Google\\ndrive here right so I'm going to I'm\\ngoing to I'm going to show you exactly\\nwhat happens after we yes or no here so\\num once we grab that file because we\\nneed to be able to get that file that\\nthe user has uploaded and save it\\nsomewhere so in our case we're using it\\nwe're we're putting it in our Google\\nDrive so as you can see right here now\\nnow I there's I mean there's a duplicate\\none because I added that earlier but as\\nyou can see this file or this invoice is\\nnow in our Google Drive so we can always\\nhave access to this from a later Point\\nall right so now let's go ahead and take\\na look at what happens when we press yes\\nhere so now if I click on test workflow\\nand if I click on yes so the data is\\ncorrect so now it says great so it went\\nthrough so now as you can see right\\nhere this is a Tex because we responded\\nwith yes so therefore it went to this\\nswitch note right here so in this switch\\nnote we're just giving it a uh three\\ndifferent uh inputs and output meaning\\none is yes no and then also which\\npayment method right and the for the\\npayment method we're giving this three\\noption card cash and bank so let's go\\nahead and take a look at that so\\nnow user is able to select whether it's\\na card bank or cash right so let's go\\nahead and say it is going to be a bank\\nthis time and now you will see I click\\non test workflow now it's listening I'm\\ngoing to say\\nbank and it's going to go ahead and\\nprocess that in the bottom it's going to\\nsend it to this route right because this\\nis the payments so now uh let this let's\\ngo ahead and let this finish all right\\nthere you go says it successfully\\nupdated the database so if I go back to\\nmy oops I just deleted or closed\\nmy Google sheet let me go back and open\\nthis all right so our Google sheet here\\nas you can see\\nnow this was the one that came through\\nright this uh was that $755 as you can\\nsee right here right and it has zero tax\\nit didn't have an invoice number so it\\ndidn't detect invoice number that's\\nbecause that sample didn't have an\\ninvoice number so therefore I left this\\nblank invoice date the total amount and\\nthen also the payment method was Bank\\nbased on our selection right so that's\\nhow you can interact with this\\nautomation so let's go ahead and take a\\nlook at what's happening here so again\\nsame thing on a switch node so now the\\npayment has these three card cash and\\nBank option so based on the selection of\\nuser so now we're just grabbing what\\ntext or what selection what choice did\\nthe user Make and this is the text and\\nthen the chat ID because we need to be\\nable to respond back to uh the user via\\nthat uh telegram chat so now we're\\ngrabbing that information we're grabbing\\nthe row number to make sure that we're\\nmatching the invoice here the\\ninformation with the invoice here so\\nthat way we're updating the correct row\\nhere right right so that's important we\\nneed to make sure we're grabbing the\\nproper row number and now we're putting\\na limit note because we only we only\\nneed to grab one row and then we're\\nadding another edit field to make sure\\nthat we're manually now um or we're\\ncleaning the data that's coming in from\\nhere we're grabbing uh the the tax we're\\ngrabbing the total amount the invoice\\ndate the invoice number and then also\\nthe bank right or the payment method so\\nthat's what we're doing and then after\\nthat we're just going to now update that\\nrole right with all of this information\\nincluding the payment method so now\\nwe're going to delete the the RO that\\nwas already there so that we don't have\\nany duplicates and then our next step\\nwe're sending this message back to the\\nuser saying that successfully updated\\nthe database right so that's what we're\\ndoing here and you can see on the left\\nhand side that's the message that was\\nsent here and then now we're also uh\\nmoving or we're grabbing the information\\nor we're searching for that particular\\nfile and that we're going to go ahead\\nand move this and make sure that this\\ninvoice is in the correct folder and as\\nyou can see right here we have added\\nthis invoice now to our Google drive\\nright so very very useful very very\\npowerful because you can essentially add\\nthis or apply this to any automation\\nright so it doesn't have to be invoicing\\nyou can see how powerful this becomes\\nwhen you're interacting with the user\\nback and forth and based on their\\nselection it moves through the different\\nroutes so you can use the same method\\nfor example for expense approval for\\ndocument processing for even payroll\\nmanagement or approving invoices or uh\\nadditional business related expenses\\nthat you have all doing this kind of\\nhuman in Loop process where you're\\nactually sending for permission so for\\nexample if somebody is actually asking\\nyou to approve an invoice this\\nautomation could be put in a place where\\nnow the manager has the ability to\\napprove deny or reject a particular uh\\ndocument to be processed so you can see\\nthere's a lot of use cases that could be\\napplied for this uh so one of the best\\nways again I always say is that when I\\ncreate these things and when we create\\nthese things this is just for\\ninspiration I love that our community\\nmembers for example they always figure\\nout ways to uh use these templates as a\\nbase as a foundation and build on top of\\nit so that's why we have our uh\\ncollaboration our Collective wisdom tab\\nwhere people uh grab these uh templates\\nand collaborate with each other to build\\ndifferent processes and make them even\\nbetter right I that's why I have this um\\nuh weekly bi-week or bi-weekly challenge\\nactually to get prizes you can us win up\\nto\\n$125 um every other week just by\\ncreating really great workf flows and a\\nlot of people um or $200 actually not1\\n125 that's just for the first price\\nright uh so you can collaborate with\\npeople to build really useful projects\\nfor yourself for businesses you can\\nutilize this or you can monetize this to\\nsell it to somebody so there are lots of\\ngreat things that you can do so make\\nsure you join the community because it's\\nan excellent place if you're serious\\nabout learning n ATN or if you're\\nserious about learning automations in\\ngeneral to monetize it or just update\\nyour skills for your own business on\\npersonal use I'm going to put the link\\nin the description I'm going to\\nhopefully see you there thanks for\\nwatching make sure you like And\\nsubscribe the video because I've got a\\nlot of great content that's upcoming so\\nyou want to make sure you don't miss it\\nthanks for watching again I'll see you\\nin the next one\\n[Music]\\nhe\\n[Music]\", id=None, name=None, meta_data={}, embedder=None, embedding=None, usage=None, reranking_score=None)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "youtube_parser(\"https://www.youtube.com/watch?v=GTrZAitjmiI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking embedding dimensions...\n",
      "Using direct Ollama API:\n",
      "Actual dimensions from direct Ollama API: 768\n",
      "\n",
      "Using Agno OllamaEmbedder:\n",
      "Expected dimensions in config: 768\n",
      "Actual dimensions from Agno OllamaEmbedder: 768\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import ollama\n",
    "from agno.embedder.ollama import OllamaEmbedder\n",
    "\n",
    "# def check_embedding_dimensions():\n",
    "print(\"Checking embedding dimensions...\")\n",
    "\n",
    "# Direct Ollama API check\n",
    "print(\"Using direct Ollama API:\")\n",
    "try:\n",
    "    response = ollama.embeddings(model=\"nomic-embed-text:latest\", prompt=\"This is a test sentence\")\n",
    "    embedding_resp = response.get('embedding', [])\n",
    "    print(f\"Actual dimensions from direct Ollama API: {len(embedding_resp)}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error with direct Ollama API: {e}\")\n",
    "\n",
    "# Agno OllamaEmbedder check\n",
    "print(\"\\nUsing Agno OllamaEmbedder:\")\n",
    "try:\n",
    "    embedder = OllamaEmbedder(id=\"nomic-embed-text:latest\", dimensions=768)\n",
    "    text = \"This is a test sentence\"\n",
    "    embedding = embedder.get_embedding(text)\n",
    "    print(f\"Expected dimensions in config: 768\")\n",
    "    print(f\"Actual dimensions from Agno OllamaEmbedder: {len(embedding)}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error with Agno OllamaEmbedder: {e}\")\n",
    "    \n",
    "#     return\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     check_embedding_dimensions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table ai.agentic_rag_documents dropped successfully.\n",
      "Database reset complete. The table will be recreated with correct dimensions on next application run.\n"
     ]
    }
   ],
   "source": [
    "import sqlalchemy\n",
    "from sqlalchemy import text\n",
    "\n",
    "# Use the same database connection string from your application\n",
    "db_url = \"postgresql+psycopg://ai:ai@localhost:5532/ai\"\n",
    "\n",
    "# Create engine\n",
    "engine = sqlalchemy.create_engine(db_url)\n",
    "\n",
    "# Drop the vector table\n",
    "with engine.connect() as connection:\n",
    "    # Start a transaction\n",
    "    with connection.begin():\n",
    "        # Drop the table\n",
    "        connection.execute(text(\"DROP TABLE IF EXISTS ai.agentic_rag_documents\"))\n",
    "        print(\"Table ai.agentic_rag_documents dropped successfully.\")\n",
    "        \n",
    "        # Optional: If you need to recreate the schema too\n",
    "        # connection.execute(text(\"DROP SCHEMA IF EXISTS ai CASCADE\"))\n",
    "        # connection.execute(text(\"CREATE SCHEMA ai\"))\n",
    "        # print(\"Schema ai recreated.\")\n",
    "\n",
    "print(\"Database reset complete. The table will be recreated with correct dimensions on next application run.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table exists (information_schema check): False\n",
      "Confirmed table doesn't exist: (psycopg.errors.UndefinedTable) relation \"ai.agentic_rag_documents\" does not exist\n",
      "LINE 1: SELECT COUNT(*) FROM ai.agentic_rag_documents LIMIT 1\n",
      "                             ^\n",
      "[SQL: SELECT COUNT(*) FROM ai.agentic_rag_documents LIMIT 1]\n",
      "(Background on this error at: https://sqlalche.me/e/20/f405)\n",
      "Tables in 'ai' schema: ['agentic_rag_agent_sessions', 'agent_memory']\n",
      "Is 'agentic_rag_documents' in list of tables: False\n"
     ]
    }
   ],
   "source": [
    "import sqlalchemy\n",
    "from sqlalchemy import text, inspect\n",
    "\n",
    "# Use the same database connection string\n",
    "db_url = \"postgresql+psycopg://ai:ai@localhost:5532/ai\"\n",
    "engine = sqlalchemy.create_engine(db_url)\n",
    "\n",
    "# Method 1: Check using PostgreSQL information_schema\n",
    "with engine.connect() as connection:\n",
    "    result = connection.execute(text(\n",
    "        \"SELECT EXISTS (SELECT FROM information_schema.tables WHERE table_schema = 'ai' AND table_name = 'agentic_rag_documents')\"\n",
    "    ))\n",
    "    table_exists = result.scalar()\n",
    "    print(f\"Table exists (information_schema check): {table_exists}\")\n",
    "\n",
    "# Method 2: Try to select from the table (will raise an error if it doesn't exist)\n",
    "try:\n",
    "    with engine.connect() as connection:\n",
    "        connection.execute(text(\"SELECT COUNT(*) FROM ai.agentic_rag_documents LIMIT 1\"))\n",
    "        print(\"Table still exists! The deletion may have failed.\")\n",
    "except Exception as e:\n",
    "    print(f\"Confirmed table doesn't exist: {e}\")\n",
    "\n",
    "# Method 3: List all tables in the schema\n",
    "with engine.connect() as connection:\n",
    "    result = connection.execute(text(\n",
    "        \"SELECT table_name FROM information_schema.tables WHERE table_schema = 'ai'\"\n",
    "    ))\n",
    "    tables = [row[0] for row in result]\n",
    "    print(f\"Tables in 'ai' schema: {tables}\")\n",
    "    print(f\"Is 'agentic_rag_documents' in list of tables: {'agentic_rag_documents' in tables}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 tables in 'ai' schema: ['agentic_rag_agent_sessions', 'agent_memory', 'agentic_rag_documents']\n"
     ]
    }
   ],
   "source": [
    "import sqlalchemy\n",
    "from sqlalchemy import text\n",
    "\n",
    "# Use the same database connection string\n",
    "db_url = \"postgresql+psycopg://ai:ai@localhost:5532/ai\"\n",
    "engine = sqlalchemy.create_engine(db_url)\n",
    "\n",
    "# First get all tables in the schema\n",
    "with engine.connect() as connection:\n",
    "    result = connection.execute(text(\n",
    "        \"SELECT table_name FROM information_schema.tables WHERE table_schema = 'ai'\"\n",
    "    ))\n",
    "    tables = [row[0] for row in result]\n",
    "    \n",
    "    print(f\"Found {len(tables)} tables in 'ai' schema: {tables}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after 'with' statement on line 2 (4115963647.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[40], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    for table in tables:\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'with' statement on line 2\n"
     ]
    }
   ],
   "source": [
    "# Drop all tables\n",
    "with engine.connect() as connection:\n",
    "    for table in tables:\n",
    "        print(f\"Dropping table ai.{table}...\")\n",
    "        connection.execute(text(f\"DROP TABLE IF EXISTS ai.{table}\"))\n",
    "            \n",
    "    print(\"\\nAll tables dropped successfully.\")\n",
    "        \n",
    "        # Optional: Recreate schema\n",
    "        # connection.execute(text(\"DROP SCHEMA IF EXISTS ai CASCADE\"))\n",
    "        # connection.execute(text(\"CREATE SCHEMA ai\"))\n",
    "        # print(\"Schema ai recreated from scratch.\")\n",
    "\n",
    "print(\"Database reset complete. All tables will be recreated with correct dimensions on next application run.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with engine.connect() as connection:\n",
    "    result = connection.execute(text(\n",
    "            \"SELECT * FROM agent_memory\"\n",
    "\n",
    "        ))\n",
    "    # result = connection.execute(text(f\"DROP TABLE IF EXISTS agentic_rag_agent_sessions\"))\n",
    "result.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema completely reset. The application will create all tables with the correct schema on next run.\n"
     ]
    }
   ],
   "source": [
    "# Add this to your notebook to completely reset the database\n",
    "import sqlalchemy\n",
    "from sqlalchemy import text\n",
    "\n",
    "# Use the same database connection string\n",
    "db_url = \"postgresql+psycopg://ai:ai@localhost:5532/ai\"\n",
    "engine = sqlalchemy.create_engine(db_url)\n",
    "\n",
    "# Drop and recreate the schema\n",
    "with engine.connect() as connection:\n",
    "    with connection.begin():\n",
    "        # Drop entire schema with CASCADE to remove all objects\n",
    "        connection.execute(text(\"DROP SCHEMA IF EXISTS ai CASCADE\"))\n",
    "        \n",
    "        # Recreate the schema \n",
    "        connection.execute(text(\"CREATE SCHEMA ai\"))\n",
    "        \n",
    "        print(\"Schema completely reset. The application will create all tables with the correct schema on next run.\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agno schema upgrade utility not found. Use the documentation link instead.\n"
     ]
    }
   ],
   "source": [
    "# Check if Agno has an upgrade utility\n",
    "try:\n",
    "    from agno.db.upgrade import upgrade_schema\n",
    "    \n",
    "    # Run the schema upgrade\n",
    "    upgrade_schema(db_url=\"postgresql+psycopg://ai:ai@localhost:5532/ai\")\n",
    "    print(\"Schema upgrade completed successfully.\")\n",
    "except ImportError:\n",
    "    print(\"Agno schema upgrade utility not found. Use the documentation link instead.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__abstractmethods__',\n",
       " '__annotations__',\n",
       " '__class__',\n",
       " '__class_getitem__',\n",
       " '__class_vars__',\n",
       " '__contains__',\n",
       " '__copy__',\n",
       " '__deepcopy__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__fields__',\n",
       " '__fields_set__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__get_pydantic_core_schema__',\n",
       " '__get_pydantic_json_schema__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__pretty__',\n",
       " '__private_attributes__',\n",
       " '__pydantic_complete__',\n",
       " '__pydantic_computed_fields__',\n",
       " '__pydantic_core_schema__',\n",
       " '__pydantic_custom_init__',\n",
       " '__pydantic_decorators__',\n",
       " '__pydantic_extra__',\n",
       " '__pydantic_fields__',\n",
       " '__pydantic_fields_set__',\n",
       " '__pydantic_generic_metadata__',\n",
       " '__pydantic_init_subclass__',\n",
       " '__pydantic_parent_namespace__',\n",
       " '__pydantic_post_init__',\n",
       " '__pydantic_private__',\n",
       " '__pydantic_root_model__',\n",
       " '__pydantic_serializer__',\n",
       " '__pydantic_validator__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__replace__',\n",
       " '__repr__',\n",
       " '__repr_args__',\n",
       " '__repr_name__',\n",
       " '__repr_recursion__',\n",
       " '__repr_str__',\n",
       " '__rich_repr__',\n",
       " '__setattr__',\n",
       " '__setitem__',\n",
       " '__setstate__',\n",
       " '__signature__',\n",
       " '__sizeof__',\n",
       " '__slots__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_abc_impl',\n",
       " '_calculate_keys',\n",
       " '_check_frozen',\n",
       " '_copy_and_set_values',\n",
       " '_get_value',\n",
       " '_iter',\n",
       " 'construct',\n",
       " 'copy',\n",
       " 'details',\n",
       " 'dict',\n",
       " 'digest',\n",
       " 'from_orm',\n",
       " 'get',\n",
       " 'json',\n",
       " 'model',\n",
       " 'model_computed_fields',\n",
       " 'model_config',\n",
       " 'model_construct',\n",
       " 'model_copy',\n",
       " 'model_dump',\n",
       " 'model_dump_json',\n",
       " 'model_extra',\n",
       " 'model_fields',\n",
       " 'model_fields_set',\n",
       " 'model_json_schema',\n",
       " 'model_parametrized_name',\n",
       " 'model_post_init',\n",
       " 'model_rebuild',\n",
       " 'model_validate',\n",
       " 'model_validate_json',\n",
       " 'model_validate_strings',\n",
       " 'modified_at',\n",
       " 'parse_file',\n",
       " 'parse_obj',\n",
       " 'parse_raw',\n",
       " 'schema',\n",
       " 'schema_json',\n",
       " 'size',\n",
       " 'update_forward_refs',\n",
       " 'validate']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'agno.tools.chat_history'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01magno\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_history\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_chat_history\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'agno.tools.chat_history'"
     ]
    }
   ],
   "source": [
    "from agno.tools.chat_history import get_chat_history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
